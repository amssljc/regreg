{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fused LASSO with sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides some ways to solve the sparse fused LASSO problem\n",
    "\n",
    "$$\n",
    "\\frac{1}{2}\\|y - \\beta\\|^2_2 + \\lambda_{1}\\|D\\beta\\|_{1} + \\lambda_2 \\|\\beta\\|_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# third party imports\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "from scipy import sparse\n",
    "\n",
    "# the regreg import\n",
    "import regreg.api as rr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the CGH data from the R package cghFLasso. You will have to have installed the package 'cghFLasso' in R, as well as installed rpy2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rpy2.robjects as ri\n",
    "ri.r('''\n",
    "# You \n",
    "library(cghFLasso)\n",
    "data(CGH)\n",
    "Y = CGH$GBM.y\n",
    "''')\n",
    "Y = np.array(ri.r('Y'))\n",
    "n = Y.shape[0]\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.scatter(np.arange(n), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify two penalties, one for \"smoothness\", i.e. piecewise constant behaviour, the other for sparsity. For \"smoothness\" we need to create the\n",
    "matrix of first order differences. There is a class of affine transforms in {\\bf regreg.affine} that can compute this and return it as a \n",
    "sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = rr.signal_approximator(Y)\n",
    "sparsity = rr.l1norm(n, lagrange=0.3)\n",
    "print rr.__file__\n",
    "import regreg.affine.fused_lasso as FL\n",
    "from regreg.affine.fused_lasso import difference_transform\n",
    "D = difference_transform(np.arange(n), order=1, sorted=True)\n",
    "\n",
    "# Let's just verify it is the matrix of first order differences\n",
    "print D[:4,:5].todense()\n",
    "\n",
    "fused = rr.l1norm.linear(D, lagrange=2.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create the problem. We will solve this as a dual problem where the primal objective is {\\bf loss}=${\\cal L}$ so the dual objective is ${\\cal L}^*(-u_s-D^Tu_f)$ with $u_s$ dual variables for the sparsity\n",
    "term and $u_f$ dual variables for the fused term.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "problem = rr.dual_problem.fromprimal(loss, sparsity, fused)\n",
    "smooth_and_sparse_coefs = problem.solve(tol=1.e-14)\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.plot(np.arange(n), smooth_and_sparse_coefs, linewidth=3, c='r')\n",
    "pylab.scatter(np.arange(n), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fused LASSO without sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also solve the problem without the sparsity penalty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "problem = rr.dual_problem.fromprimal(loss, fused)\n",
    "smooth_coefs = problem.solve(tol=1.e-14)\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.plot(np.arange(n), smooth_coefs, linewidth=3, c='r')\n",
    "pylab.scatter(np.arange(n), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fused LASSO via smoothing the TV term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than solve the dual problem, we might also consider smoothing the {\\bf fused} penalty and keeping a sparsity penalty. The smoothing is accomplished by using\n",
    "a small quadratic term. This results in a separable problem with just the $\\ell_1$ penalty. There are now several smooth terms, we lump\n",
    "them together in the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sq = rr.identity_quadratic(0.001, 0, 0, 0)\n",
    "fused_smooth = fused.smoothed(sq)\n",
    "problem = rr.container(loss, fused_smooth, sparsity)\n",
    "smoothed_smooth_and_sparse_coefs = problem.solve()\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.plot(np.arange(n), smoothed_smooth_and_sparse_coefs, linewidth=4, c='r', label='Smoothed')\n",
    "pylab.plot(np.arange(n), smooth_and_sparse_coefs, linewidth=2, c='yellow', linestyle='--', label='Unsmoothed')\n",
    "pylab.scatter(np.arange(n), Y, facecolor='gray')\n",
    "pylab.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also solve the problem without the sparsity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fused_smooth = fused.smoothed(sq)\n",
    "problem = rr.container(loss, fused_smooth)\n",
    "smoothed_smooth_coefs = problem.solve()\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.plot(np.arange(n), smoothed_smooth_coefs, linewidth=4, c='r', label='Smoothed')\n",
    "pylab.plot(np.arange(n), smooth_coefs, linewidth=2, c='yellow', linestyle='--', label='Unsmoothed')\n",
    "pylab.scatter(np.arange(n), Y, facecolor='gray')\n",
    "pylab.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding offsets to penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, we may want to shrink to some value other than zero. This can be achieved by adding an offset to the seminorm. For instance, we might\n",
    "want to shrink towards 2. We might do this by solving\n",
    "$$ \\frac{1}{2}||y - \\beta||^2_2 + \\lambda_{1}||D\\beta||_{1} + \\lambda_2 \\|\\beta-2\\|_1 $$\n",
    "This is an offset of -2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparsity_2 = rr.l1norm(n, offset=-2*np.ones(n), lagrange=1)\n",
    "problem = rr.dual_problem.fromprimal(loss, sparsity_2, fused)\n",
    "smooth_and_sparse2_coefs = problem.solve(tol=1.e-14)\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.plot(np.arange(n), smooth_and_sparse2_coefs, linewidth=3, c='r')\n",
    "pylab.scatter(np.arange(n), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing the penalty on the sparsity_2 term, we shrink all the way to the constant solution $2  \\cdot \\pmb{1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparsity_2.lagrange = 3\n",
    "problem = rr.dual_problem.fromprimal(loss, sparsity_2, fused)\n",
    "smooth_and_sparse2_coefs = problem.solve(tol=1.e-14)\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.plot(np.arange(n), smooth_and_sparse2_coefs, linewidth=3, c='r')\n",
    "pylab.scatter(np.arange(n), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can set the offset to be some other vector as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparsity_2.offset = -np.arange(n) * 2. / n\n",
    "problem = rr.dual_problem.fromprimal(loss, sparsity_2, fused)\n",
    "smooth_and_sparse2_coefs = problem.solve(tol=1.e-14)\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.plot(np.arange(n), smooth_and_sparse2_coefs, linewidth=3, c='r')\n",
    "pylab.scatter(np.arange(n), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also try a constrained form of the problem, rather than the Lagrange form. For instance, we might\n",
    "constrain the $\\ell_1$ norm to be less than or equal to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparsity_bound = rr.l1norm(n, bound=50)\n",
    "problem = rr.dual_problem.fromprimal(loss, sparsity_bound, fused)\n",
    "smooth_and_sparse_coefs = problem.solve(tol=1.e-14)\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.plot(np.arange(n), smooth_and_sparse_coefs, linewidth=3, c='r')\n",
    "pylab.scatter(np.arange(n), Y)\n",
    "print 'sparsity %0.1f' % np.fabs(smooth_and_sparse_coefs).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we might constrain the $\\ell_1$ norm of $D\\hat{\\beta}$ to be less than 10, and keep the Lagrange form for the sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fused_bound = rr.l1norm.linear(D, bound=10)\n",
    "problem = rr.dual_problem.fromprimal(loss, sparsity, fused_bound)\n",
    "smooth_and_sparse_coefs = problem.solve(tol=1.e-14)\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.plot(np.arange(n), smooth_and_sparse_coefs, linewidth=3, c='r')\n",
    "pylab.scatter(np.arange(n), Y)\n",
    "print 'fused %0.1f' % np.fabs(D*smooth_and_sparse_coefs).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also keep them both in bound form. At a solution, of course, they may not be both tight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "problem = rr.dual_problem.fromprimal(loss, sparsity_bound, fused_bound)\n",
    "smooth_and_sparse_coefs = problem.solve(tol=1.e-14)\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.plot(np.arange(n), smooth_and_sparse_coefs, linewidth=3, c='r')\n",
    "pylab.scatter(np.arange(n), Y)\n",
    "print 'sparsity: %0.1f' % np.fabs(smooth_and_sparse_coefs).sum()\n",
    "print 'fused: %0.1f' % np.fabs(D*smooth_and_sparse_coefs).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparsity_bound.bound = 500\n",
    "problem = rr.dual_problem.fromprimal(loss, sparsity_bound, fused_bound)\n",
    "smooth_and_sparse_coefs = problem.solve(tol=1.e-14)\n",
    "pylab.figure(figsize=(20,10))\n",
    "pylab.plot(np.arange(n), smooth_and_sparse_coefs, linewidth=3, c='r')\n",
    "pylab.scatter(np.arange(n), Y)\n",
    "print 'sparsity: %0.1f' % np.fabs(smooth_and_sparse_coefs).sum()\n",
    "print 'fused: %0.1f' % np.fabs(D*smooth_and_sparse_coefs).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
